{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dd0cd9",
   "metadata": {},
   "source": [
    "# Love letter reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a858ca",
   "metadata": {},
   "source": [
    "### Finetune a GPT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b392bf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d01c9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2413bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38b27f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d9a82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Such as in evening silence come the first part of the night, so the next morning (as always it is on Sundays) we return on the way home.\\nI am on the last-minute of every waking call. I'm not doing anything\"}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Such as in evening silence come\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e3207",
   "metadata": {},
   "source": [
    "with open(\"combined.txt\", \"w\") as fh:\n",
    "    fh.write(open(\"combined-20000.txt\").read()[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b175b647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/Users/voruin/.cache/huggingface/datasets/text/default-649a8d2ae5e0a169/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a6b22dfa2b417face5bfcb81c2a2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = datasets.load_dataset('text', data_files=\"combined.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "debd5e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenized_training_data = training_data.map(\n",
    "    lambda x: tokenizer(x['text']),\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcfccbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = 64\n",
    "# magic from https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "lm_training_data = tokenized_training_data.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "356b7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee34f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  train_dataset=lm_training_data['train'],\n",
    "                  args=TrainingArguments(\n",
    "                      output_dir='distilgpt2-finetune-victorianLovePoems',\n",
    "                      num_train_epochs=1,\n",
    "                      do_train=True,\n",
    "                      do_eval=False\n",
    "                  ),\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a480839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 366\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=46, training_loss=4.881471716839334, metrics={'train_runtime': 21.6837, 'train_samples_per_second': 16.879, 'train_steps_per_second': 2.121, 'total_flos': 5977163169792.0, 'train_loss': 4.881471716839334, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48e1d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilgpt2-finetune-victorianLovePoems\n",
      "Configuration saved in distilgpt2-finetune-victorianLovePoems/config.json\n",
      "Model weights saved in distilgpt2-finetune-victorianLovePoems/pytorch_model.bin\n",
      "tokenizer config file saved in distilgpt2-finetune-victorianLovePoems/tokenizer_config.json\n",
      "Special tokens file saved in distilgpt2-finetune-victorianLovePoems/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d780b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'And days may pass in gay confusion, in our time. And on the eve of the 2015 presidential election, we must take care of the LGBT community. This year has had a profound and profound, multifaceted, and deeply profound impact on gay politics.\\n\\n\\n\\n\\nThis year marks the last time a LGBT-themed ad campaign has been launched that has gone on-the-air against the LGBT community.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"And days may pass in gay confusion,\", max_length=100)[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4953b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokenizer = AutoTokenizer.from_pretrained('distilgpt2-finetune-victorianLovePoems')\n",
    "my_model = AutoModelForCausalLM.from_pretrained('distilgpt2-finetune-victorianLovePoems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1859aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_generator = pipeline(\"text-generation\", model=my_model, tokenizer=my_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2493b9",
   "metadata": {},
   "source": [
    "my_generator(\"And days may pass in gay confusion,\")[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a334220",
   "metadata": {},
   "source": [
    "my_generator(\"And days may pass in gay confusion,\")[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29b0f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "639cd8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator(prompt, min_length=50, max_length=200):\n",
    "    generated_text = my_generator(prompt)[0]['generated_text']\n",
    "    while len(generated_text) < min_length or len(generated_text) > max_length or not re.search(r'[.!?]$', generated_text):\n",
    "        print(generated_text)\n",
    "        generated_text = my_generator(prompt)[0]['generated_text']\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b36cd7",
   "metadata": {},
   "source": [
    "poem_generator(\"Did you miss me?\", min_length=80, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfb5003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator2(prompt, min_length=50, max_length=200):\n",
    "\n",
    "    generated_text = my_generator(prompt)[0]['generated_text']\n",
    "    \n",
    "    while len(generated_text) < min_length or len(generated_text) > max_length:\n",
    "        generated_text = my_generator(prompt)[0]['generated_text']\n",
    "\n",
    "    if re.search(r'[.!?]$', generated_text):\n",
    "        generated_text=generated_text\n",
    "        \n",
    "    elif not re.search(r'[.!?]$', generated_text):\n",
    "        generated_text=generated_text+\" ...\"\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95836607",
   "metadata": {},
   "source": [
    "poem_generator2(\"None would miss me in all the world,\", min_length=80, max_length=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c1d71",
   "metadata": {},
   "source": [
    "poem_generator2(\"I miss you,\", min_length=100, max_length=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5730f",
   "metadata": {},
   "source": [
    "### test on Markovify (not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7db23b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cf182c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_mark = markovify.Text(text_lovePoems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6150eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On all her loveliness.\n"
     ]
    }
   ],
   "source": [
    "print(generator_mark.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2ac51c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus am I mine own prison.\n"
     ]
    }
   ],
   "source": [
    "print(generator_mark.make_short_sentence(50, test_output=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63e1af78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Though I tarry, wait for another life, for more suffering, To give them birth; another life and many more tears And love, to make her eat.\n"
     ]
    }
   ],
   "source": [
    "print(generator_mark.make_short_sentence(400, test_output=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09b4f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_model = markovify.NewlineText(text_lovePoems, state_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f22102be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles, tears, hoped for evermore\n",
      "Where the goblins cry:\n",
      "Laura spoke in pain;\n",
      "No later light with haste\n",
      "It lurks like mine be\n",
      "Many in love:\n",
      "One call’d her resistance,\n",
      "It was in secret steps, thou showest me in rosy morn,\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print(poems_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0d552fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The heart\n"
     ]
    }
   ],
   "source": [
    "print(poems_model.make_sentence(test_output=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c51e68",
   "metadata": {},
   "source": [
    "### giving prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lovePoems = open(\"combined.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2461da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_lines = text_lovePoems.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3af9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleneighbors import SimpleNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "697da966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b26d6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6022812",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in poems_lines:\n",
    "    if line !=\"\":\n",
    "        lines.append(line.replace('“', '').replace('”', '').strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88351f",
   "metadata": {},
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5ade021",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_lines = random.sample(lines,len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a9e75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(sent):\n",
    "    return nlp(sent, disable=['parser', 'tagger', 'ner']).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50cbc875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/voruin/miniconda3/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "embeddings = [summary(line) for line in sampled_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70d1a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = SimpleNeighbors(300)\n",
    "for vec, line in zip(embeddings, sampled_lines):\n",
    "    lookup.add_one(line, vec)\n",
    "lookup.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9df25a2",
   "metadata": {},
   "source": [
    "lookup.nearest(summary(\"miss\"), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7430ef",
   "metadata": {},
   "source": [
    "poem_generator2(\"And wonder what you’ve missed.\", min_length=100, max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7bc8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "649c50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "input_prompt=\"I sit here, an arch-villain of romance, thinking about you.\" ## change here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d64c9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text_lovePoems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1dd1f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in list(doc) if w.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27455d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "verbs = [w for w in words if w.pos_ == \"VERB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "669bf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_string = [str(w) for w in nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f085d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking\n"
     ]
    }
   ],
   "source": [
    "doc_prompt = nlp(input_prompt)\n",
    "words_in_prompt = [w for w in list(doc_prompt) if w.is_alpha]\n",
    "nouns_in_prompt = [w for w in words_in_prompt if w.pos_ == \"NOUN\"]\n",
    "verbs_in_prompt = [w for w in words_in_prompt if w.pos_ == \"VERB\"]\n",
    "\n",
    "if len(verbs_in_prompt) > 0:\n",
    "    prompt_word = random.choice(verbs_in_prompt)\n",
    "elif len(nouns_in_prompt) > 0:\n",
    "    prompt_word = random.choice(nouns_in_prompt)\n",
    "else:\n",
    "    prompt_word = random.choice(words)\n",
    "\n",
    "print(prompt_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d910f851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "nearst_corpus_lists = lookup.nearest(summary(str(prompt_word)), 10)\n",
    "content_generated = poem_generator2(random.choice(nearst_corpus_lists), min_length=100, max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24cce957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And all the world and I seemed much less cold,I sat all day,Even half my night,I had no more time to think.You shall not think I love you.But you shall not think I love you,Nor did you think ...'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(content_generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
